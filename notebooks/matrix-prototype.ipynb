{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from autograd import grad\n",
    "\n",
    "import autograd.numpy as np\n",
    "import pickle as pkl\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATV</th>\n",
       "      <th>DRV</th>\n",
       "      <th>FPV</th>\n",
       "      <th>IDV</th>\n",
       "      <th>LPV</th>\n",
       "      <th>NFV</th>\n",
       "      <th>SQV</th>\n",
       "      <th>SeqID</th>\n",
       "      <th>TPV</th>\n",
       "      <th>seqid</th>\n",
       "      <th>sequence</th>\n",
       "      <th>sequence_object</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>16.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2996-0</td>\n",
       "      <td>PQITLWQRPIVTIKIGGQLKEALLDTGADDTVLEDVNLPGRWKPKM...</td>\n",
       "      <td>ID: 2996-0\\nName: &lt;unknown name&gt;\\nDescription:...</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>16.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2996-1</td>\n",
       "      <td>PQITLWQRPIVTIKIGGQLKEALLDTGADDTVLEDVNLPGRWKPKM...</td>\n",
       "      <td>ID: 2996-1\\nName: &lt;unknown name&gt;\\nDescription:...</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4387-0</td>\n",
       "      <td>PQITLWQRPLVTIKVGGQLKEALLDTGADDTVLEDMELPGRWKPKM...</td>\n",
       "      <td>ID: 4387-0\\nName: &lt;unknown name&gt;\\nDescription:...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4387-1</td>\n",
       "      <td>PQITLWQRPLVTIKVGGQLKEALLDTGADDTVLEDMELPGRWKPKM...</td>\n",
       "      <td>ID: 4387-1\\nName: &lt;unknown name&gt;\\nDescription:...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4387-2</td>\n",
       "      <td>PQITLWQRPLVTIKVGGQLKEALLDTGADDTVLEDMELPGRWKPKM...</td>\n",
       "      <td>ID: 4387-2\\nName: &lt;unknown name&gt;\\nDescription:...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ATV  DRV  FPV   IDV  LPV   NFV   SQV  SeqID  TPV   seqid  \\\n",
       "0  NaN  NaN  2.5  16.3  NaN  38.6  16.1   2996  NaN  2996-0   \n",
       "1  NaN  NaN  2.5  16.3  NaN  38.6  16.1   2996  NaN  2996-1   \n",
       "2  NaN  NaN  0.7   0.8  NaN   0.8   1.1   4387  NaN  4387-0   \n",
       "3  NaN  NaN  0.7   0.8  NaN   0.8   1.1   4387  NaN  4387-1   \n",
       "4  NaN  NaN  0.7   0.8  NaN   0.8   1.1   4387  NaN  4387-2   \n",
       "\n",
       "                                            sequence  \\\n",
       "0  PQITLWQRPIVTIKIGGQLKEALLDTGADDTVLEDVNLPGRWKPKM...   \n",
       "1  PQITLWQRPIVTIKIGGQLKEALLDTGADDTVLEDVNLPGRWKPKM...   \n",
       "2  PQITLWQRPLVTIKVGGQLKEALLDTGADDTVLEDMELPGRWKPKM...   \n",
       "3  PQITLWQRPLVTIKVGGQLKEALLDTGADDTVLEDMELPGRWKPKM...   \n",
       "4  PQITLWQRPLVTIKVGGQLKEALLDTGADDTVLEDMELPGRWKPKM...   \n",
       "\n",
       "                                     sequence_object  weight  \n",
       "0  ID: 2996-0\\nName: <unknown name>\\nDescription:...    0.50  \n",
       "1  ID: 2996-1\\nName: <unknown name>\\nDescription:...    0.50  \n",
       "2  ID: 4387-0\\nName: <unknown name>\\nDescription:...    0.25  \n",
       "3  ID: 4387-1\\nName: <unknown name>\\nDescription:...    0.25  \n",
       "4  ID: 4387-2\\nName: <unknown name>\\nDescription:...    0.25  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the data file that contains the HIV protease data\n",
    "\n",
    "df = pd.read_csv('../data/hiv_data/hiv-protease-data-expanded.csv', index_col=0)\n",
    "df = df.dropna(subset=['FPV'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open the numpy array of all graphs' data.\n",
    "graph_arr = np.load('../data/feat_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open the pickles that contain the graph information and node-nbr information.\n",
    "def unpickle_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    return data\n",
    "\n",
    "graph_idxs = unpickle_data('../data/graph_idxs.pkl')\n",
    "graph_nodes = unpickle_data('../data/graph_nodes.pkl')\n",
    "nodes_nbrs = unpickle_data('../data/nodes_nbrs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['61143-1', '230072-0', '109450-2', '68350-0', '86690-0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graph_idxs.keys())[0:5]\n",
    "# len(graph_idxs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('61143-1',\n",
       " {461513: 'A70LYS',\n",
       "  461514: 'A19LEU',\n",
       "  461515: 'B93LEU',\n",
       "  461516: 'B73GLY',\n",
       "  461517: 'A36MET',\n",
       "  461518: 'B49GLY',\n",
       "  461519: 'A12THR',\n",
       "  461520: 'B14LYS',\n",
       "  461521: 'A24LEU',\n",
       "  461522: 'B68GLY',\n",
       "  461523: 'B4THR',\n",
       "  461524: 'A88ASN',\n",
       "  461525: 'B2GLN',\n",
       "  461526: 'A29ASP',\n",
       "  461527: 'A6TRP',\n",
       "  461528: 'A33PHE',\n",
       "  461529: 'A32VAL',\n",
       "  461530: 'A3ILE',\n",
       "  461531: 'B75VAL',\n",
       "  461532: 'A42TRP',\n",
       "  461533: 'A34GLU',\n",
       "  461534: 'A65GLU',\n",
       "  461535: 'A53PHE',\n",
       "  461536: 'A85ILE',\n",
       "  461537: 'B6TRP',\n",
       "  461538: 'A94GLY',\n",
       "  461539: 'B30ASP',\n",
       "  461540: 'A52GLY',\n",
       "  461541: 'B66ILE',\n",
       "  461542: 'B98ASN',\n",
       "  461543: 'B70LYS',\n",
       "  461544: 'B32VAL',\n",
       "  461545: 'A2GLN',\n",
       "  461546: 'B79PRO',\n",
       "  461547: 'A44PRO',\n",
       "  461548: 'A22ALA',\n",
       "  461549: 'B28ALA',\n",
       "  461550: 'B94GLY',\n",
       "  461551: 'B22ALA',\n",
       "  461552: 'B40GLY',\n",
       "  461553: 'B76LEU',\n",
       "  461554: 'B15ILE',\n",
       "  461555: 'A28ALA',\n",
       "  461556: 'A71VAL',\n",
       "  461557: 'B57LYS',\n",
       "  461558: 'B71VAL',\n",
       "  461559: 'B78GLY',\n",
       "  461560: 'A20LYS',\n",
       "  461561: 'B82ALA',\n",
       "  461562: 'A13ILE',\n",
       "  461563: 'A72VAL',\n",
       "  461564: 'B19LEU',\n",
       "  461565: 'B18GLN',\n",
       "  461566: 'A21GLU',\n",
       "  461567: 'A96THR',\n",
       "  461568: 'B13ILE',\n",
       "  461569: 'A39PRO',\n",
       "  461570: 'B55LYS',\n",
       "  461571: 'B72VAL',\n",
       "  461572: 'B9PRO',\n",
       "  461573: 'A55LYS',\n",
       "  461574: 'B7GLN',\n",
       "  461575: 'A41LYS',\n",
       "  461576: 'B38LEU',\n",
       "  461577: 'A17GLY',\n",
       "  461578: 'B42TRP',\n",
       "  461579: 'A48GLY',\n",
       "  461580: 'A43LYS',\n",
       "  461581: 'A5LEU',\n",
       "  461582: 'B58GLN',\n",
       "  461583: 'A73GLY',\n",
       "  461584: 'B24LEU',\n",
       "  461585: 'B21GLU',\n",
       "  461586: 'A35GLU',\n",
       "  461587: 'A66ILE',\n",
       "  461588: 'B51GLY',\n",
       "  461589: 'B84ILE',\n",
       "  461590: 'B63PRO',\n",
       "  461591: 'B81PRO',\n",
       "  461592: 'A89LEU',\n",
       "  461593: 'A56VAL',\n",
       "  461594: 'A78GLY',\n",
       "  461595: 'A69HIS',\n",
       "  461596: 'B89LEU',\n",
       "  461597: 'A54VAL',\n",
       "  461598: 'A77VAL',\n",
       "  461599: 'B61GLN',\n",
       "  461600: 'B17GLY',\n",
       "  461601: 'B41LYS',\n",
       "  461602: 'A60ASP',\n",
       "  461603: 'B74THR',\n",
       "  461604: 'B43LYS',\n",
       "  461605: 'B69HIS',\n",
       "  461606: 'B54VAL',\n",
       "  461607: 'B3ILE',\n",
       "  461608: 'A23LEU',\n",
       "  461609: 'A68GLY',\n",
       "  461610: 'A18GLN',\n",
       "  461611: 'A9PRO',\n",
       "  461612: 'B96THR',\n",
       "  461613: 'A61GLN',\n",
       "  461614: 'A1PRO',\n",
       "  461615: 'A83ASN',\n",
       "  461616: 'A11VAL',\n",
       "  461617: 'A27GLY',\n",
       "  461618: 'A59TYR',\n",
       "  461619: 'B23LEU',\n",
       "  461620: 'B77VAL',\n",
       "  461621: 'A46LEU',\n",
       "  461622: 'B44PRO',\n",
       "  461623: 'A7GLN',\n",
       "  461624: 'A63PRO',\n",
       "  461625: 'B95CYS',\n",
       "  461626: 'B67CYS',\n",
       "  461627: 'A91THR',\n",
       "  461628: 'A92GLN',\n",
       "  461629: 'A8ARG',\n",
       "  461630: 'A79PRO',\n",
       "  461631: 'A87ARG',\n",
       "  461632: 'B86GLY',\n",
       "  461633: 'B48GLY',\n",
       "  461634: 'A47ILE',\n",
       "  461635: 'A84ILE',\n",
       "  461636: 'A75VAL',\n",
       "  461637: 'A90MET',\n",
       "  461638: 'A57LYS',\n",
       "  461639: 'B36MET',\n",
       "  461640: 'B34GLU',\n",
       "  461641: 'A93LEU',\n",
       "  461642: 'B46LEU',\n",
       "  461643: 'A14LYS',\n",
       "  461644: 'B47ILE',\n",
       "  461645: 'B11VAL',\n",
       "  461646: 'B87ARG',\n",
       "  461647: 'A67CYS',\n",
       "  461648: 'A37ASP',\n",
       "  461649: 'A50ILE',\n",
       "  461650: 'A25ASP',\n",
       "  461651: 'B80THR',\n",
       "  461652: 'B97LEU',\n",
       "  461653: 'B60ASP',\n",
       "  461654: 'A16ALA',\n",
       "  461655: 'A64ILE',\n",
       "  461656: 'A31THR',\n",
       "  461657: 'A82ALA',\n",
       "  461658: 'A99PHE',\n",
       "  461659: 'A98ASN',\n",
       "  461660: 'A45LYS',\n",
       "  461661: 'B83ASN',\n",
       "  461662: 'B65GLU',\n",
       "  461663: 'A74THR',\n",
       "  461664: 'B20LYS',\n",
       "  461665: 'B35GLU',\n",
       "  461666: 'B12THR',\n",
       "  461667: 'B90MET',\n",
       "  461668: 'A95CYS',\n",
       "  461669: 'B53PHE',\n",
       "  461670: 'A4THR',\n",
       "  461671: 'B45LYS',\n",
       "  461672: 'B85ILE',\n",
       "  461673: 'A76LEU',\n",
       "  461674: 'B59TYR',\n",
       "  461675: 'A58GLN',\n",
       "  461676: 'A62ILE',\n",
       "  461677: 'B27GLY',\n",
       "  461678: 'A49GLY',\n",
       "  461679: 'B52GLY',\n",
       "  461680: 'B33PHE',\n",
       "  461681: 'A97LEU',\n",
       "  461682: 'A26THR',\n",
       "  461683: 'A15ILE',\n",
       "  461684: 'B64ILE',\n",
       "  461685: 'B31THR',\n",
       "  461686: 'B1PRO',\n",
       "  461687: 'B26THR',\n",
       "  461688: 'A40GLY',\n",
       "  461689: 'A30ASP',\n",
       "  461690: 'B29ASP',\n",
       "  461691: 'B62ILE',\n",
       "  461692: 'A51GLY',\n",
       "  461693: 'B99PHE',\n",
       "  461694: 'A80THR',\n",
       "  461695: 'A86GLY',\n",
       "  461696: 'A10ILE',\n",
       "  461697: 'A38LEU',\n",
       "  461698: 'B5LEU',\n",
       "  461699: 'A81PRO',\n",
       "  461700: 'B92GLN',\n",
       "  461701: 'B16ALA',\n",
       "  461702: 'B10ILE',\n",
       "  461703: 'B25ASP',\n",
       "  461704: 'B37ASP',\n",
       "  461705: 'B88ASN',\n",
       "  461706: 'B50ILE',\n",
       "  461707: 'B39PRO',\n",
       "  461708: 'B91THR',\n",
       "  461709: 'B56VAL',\n",
       "  461710: 'B8ARG'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graph_nodes.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [0, 23, 46])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nodes_nbrs.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep track of only those that are in both the graph_idxs and in the df['seqid']\n",
    "intersect = set(df['seqid'].values).intersection(graph_idxs.keys())\n",
    "len(intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a reduced list of graph_idxs.\n",
    "graph_idxs_red = dict()\n",
    "graph_nodes_red = dict()\n",
    "for g in intersect:\n",
    "    graph_idxs_red[g] = graph_idxs[g]\n",
    "    graph_nodes_red[g] = graph_nodes[g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[535066,\n",
       " 535067,\n",
       " 535068,\n",
       " 535069,\n",
       " 535070,\n",
       " 535071,\n",
       " 535072,\n",
       " 535073,\n",
       " 535074,\n",
       " 535075,\n",
       " 535076,\n",
       " 535077,\n",
       " 535078,\n",
       " 535079,\n",
       " 535080,\n",
       " 535081,\n",
       " 535082,\n",
       " 535083,\n",
       " 535084,\n",
       " 535085,\n",
       " 535086,\n",
       " 535087,\n",
       " 535088,\n",
       " 535089,\n",
       " 535090,\n",
       " 535091,\n",
       " 535092,\n",
       " 535093,\n",
       " 535094,\n",
       " 535095,\n",
       " 535096,\n",
       " 535097,\n",
       " 535098,\n",
       " 535099,\n",
       " 535100,\n",
       " 535101,\n",
       " 535102,\n",
       " 535103,\n",
       " 535104,\n",
       " 535105,\n",
       " 535106,\n",
       " 535107,\n",
       " 535108,\n",
       " 535109,\n",
       " 535110,\n",
       " 535111,\n",
       " 535112,\n",
       " 535113,\n",
       " 535114,\n",
       " 535115,\n",
       " 535116,\n",
       " 535117,\n",
       " 535118,\n",
       " 535119,\n",
       " 535120,\n",
       " 535121,\n",
       " 535122,\n",
       " 535123,\n",
       " 535124,\n",
       " 535125,\n",
       " 535126,\n",
       " 535127,\n",
       " 535128,\n",
       " 535129,\n",
       " 535130,\n",
       " 535131,\n",
       " 535132,\n",
       " 535133,\n",
       " 535134,\n",
       " 535135,\n",
       " 535136,\n",
       " 535137,\n",
       " 535138,\n",
       " 535139,\n",
       " 535140,\n",
       " 535141,\n",
       " 535142,\n",
       " 535143,\n",
       " 535144,\n",
       " 535145,\n",
       " 535146,\n",
       " 535147,\n",
       " 535148,\n",
       " 535149,\n",
       " 535150,\n",
       " 535151,\n",
       " 535152,\n",
       " 535153,\n",
       " 535154,\n",
       " 535155,\n",
       " 535156,\n",
       " 535157,\n",
       " 535158,\n",
       " 535159,\n",
       " 535160,\n",
       " 535161,\n",
       " 535162,\n",
       " 535163,\n",
       " 535164,\n",
       " 535165,\n",
       " 535166,\n",
       " 535167,\n",
       " 535168,\n",
       " 535169,\n",
       " 535170,\n",
       " 535171,\n",
       " 535172,\n",
       " 535173,\n",
       " 535174,\n",
       " 535175,\n",
       " 535176,\n",
       " 535177,\n",
       " 535178,\n",
       " 535179,\n",
       " 535180,\n",
       " 535181,\n",
       " 535182,\n",
       " 535183,\n",
       " 535184,\n",
       " 535185,\n",
       " 535186,\n",
       " 535187,\n",
       " 535188,\n",
       " 535189,\n",
       " 535190,\n",
       " 535191,\n",
       " 535192,\n",
       " 535193,\n",
       " 535194,\n",
       " 535195,\n",
       " 535196,\n",
       " 535197,\n",
       " 535198,\n",
       " 535199,\n",
       " 535200,\n",
       " 535201,\n",
       " 535202,\n",
       " 535203,\n",
       " 535204,\n",
       " 535205,\n",
       " 535206,\n",
       " 535207,\n",
       " 535208,\n",
       " 535209,\n",
       " 535210,\n",
       " 535211,\n",
       " 535212,\n",
       " 535213,\n",
       " 535214,\n",
       " 535215,\n",
       " 535216,\n",
       " 535217,\n",
       " 535218,\n",
       " 535219,\n",
       " 535220,\n",
       " 535221,\n",
       " 535222,\n",
       " 535223,\n",
       " 535224,\n",
       " 535225,\n",
       " 535226,\n",
       " 535227,\n",
       " 535228,\n",
       " 535229,\n",
       " 535230,\n",
       " 535231,\n",
       " 535232,\n",
       " 535233,\n",
       " 535234,\n",
       " 535235,\n",
       " 535236,\n",
       " 535237,\n",
       " 535238,\n",
       " 535239,\n",
       " 535240,\n",
       " 535241,\n",
       " 535242,\n",
       " 535243,\n",
       " 535244,\n",
       " 535245,\n",
       " 535246,\n",
       " 535247,\n",
       " 535248,\n",
       " 535249,\n",
       " 535250,\n",
       " 535251,\n",
       " 535252,\n",
       " 535253,\n",
       " 535254,\n",
       " 535255,\n",
       " 535256,\n",
       " 535257,\n",
       " 535258,\n",
       " 535259,\n",
       " 535260,\n",
       " 535261,\n",
       " 535262,\n",
       " 535263]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_idxs_red['46213-0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659895, 36)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make one pass over the data to get the old/new index mapping, and\n",
    "# make the final graph_array that gets passed in as an input.\n",
    "\n",
    "def reindex_data_matrix(graph_idxs_red, graph_arr):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ===========\n",
    "    - graph_idxs_red: reduced graph indices\n",
    "    - graph_arr: the original matrix of (nodes by node_features)\n",
    "    \n",
    "    Returns:\n",
    "    ========\n",
    "    - graph_arr_fin: a reduced matrix of (nodes by node_features)\n",
    "    - nodes_oldnew, nodes_newold: mapping of new and old indices.\n",
    "    \"\"\"\n",
    "    # Initialize a zero-matrix. \n",
    "    idxs = np.concatenate([i for i in graph_idxs_red.values()])\n",
    "    graph_arr_fin = np.zeros(shape=graph_arr[idxs].shape)\n",
    "\n",
    "    # Initialize empty maps of graph indices from the old to the new.\n",
    "    nodes_oldnew = dict()  # {old_idx: new_idx}.\n",
    "    nodes_newold = dict()  # {new_idx: old_idx}\n",
    "\n",
    "    # Re-assign reduced graphs to the zero-matrix.\n",
    "    curr_idx = 0\n",
    "    for seqid, idxs in sorted(graph_idxs_red.items()):\n",
    "        for idx in idxs:\n",
    "            nodes_oldnew[idx] = curr_idx\n",
    "            nodes_newold[curr_idx] = idx\n",
    "            graph_arr_fin[curr_idx] = graph_arr[idx]\n",
    "            curr_idx += 1\n",
    "    return graph_arr_fin, nodes_oldnew, nodes_newold\n",
    "\n",
    "graph_arr_fin, nodes_oldnew, nodes_newold = reindex_data_matrix(graph_idxs_red, graph_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622671, 36)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_arr_fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622671"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes_oldnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622671"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes_newold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check a random sample of the indices to make sure that they are sampled correctly.\n",
    "from random import sample\n",
    "\n",
    "n_samples = 10000\n",
    "rnd_idxs = sample([i for i in range(graph_arr_fin.shape[0])], n_samples)\n",
    "for new_idx in rnd_idxs:\n",
    "    assert np.all(np.equal(graph_arr_fin[new_idx], graph_arr[nodes_newold[new_idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622671, 36)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_arr_fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally, rework the nodes_nbrs, graph_idxs, and graph_nodes dictionaries with the corrected idxs.\n",
    "# THIS IS THE KEY STEP! MUST ENCAPSULATE IN A FUNCTION!\n",
    "from collections import defaultdict\n",
    "\n",
    "def filter_and_reindex_nodes_and_neighbors(nodes_nbrs, nodes_oldnew):\n",
    "    \"\"\"\n",
    "    - nodes_nbrs: a dictionary of nodes and their neighbors.\n",
    "    - nodes_oldnew: a dictionary mapping old node indices to their new node indices.\n",
    "    \"\"\"\n",
    "    nodes_nbrs_fin = defaultdict(list)\n",
    "    \n",
    "    for node, nbrs in sorted(nodes_nbrs.items()):\n",
    "        if node in nodes_oldnew.keys():  # \n",
    "            for nbr in nbrs:\n",
    "                nodes_nbrs_fin[nodes_oldnew[node]].append(nodes_oldnew[nbr])\n",
    "    return nodes_nbrs_fin\n",
    "\n",
    "nodes_nbrs_fin = filter_and_reindex_nodes_and_neighbors(nodes_nbrs, nodes_oldnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_and_reindex_graph_idxs(graph_idxs, nodes_oldnew):\n",
    "    \"\"\"\n",
    "    - graph_idxs: a dictionary of graphs and their original indices.\n",
    "    - nodes_oldnew: a dictionary mapping old node indices to their new node indices.\n",
    "    \"\"\"\n",
    "    graph_idxs_fin = defaultdict(list)\n",
    "    for seqid, nodes in sorted(graph_idxs.items()):\n",
    "        for node in nodes:\n",
    "            if node in nodes_oldnew.keys():\n",
    "                graph_idxs_fin[seqid].append(nodes_oldnew[node])\n",
    "    return graph_idxs_fin\n",
    "\n",
    "graph_idxs_fin = filter_and_reindex_graph_idxs(graph_idxs, nodes_oldnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_and_reindex_graph_nodes(graph_nodes, nodes_oldnew):\n",
    "    \"\"\"\n",
    "    - graph_nodes: a dictionary mapping graphs to their dictionary mapping indices to node names.\n",
    "    - nodes_oldnew: a dictionary mapping old node indices to their new node indices.\n",
    "    \"\"\"    \n",
    "    graph_nodes_fin = defaultdict(dict)\n",
    "    for seqid, idx_node in sorted(graph_nodes.items()):\n",
    "        for old_idx, node_name in idx_node.items():\n",
    "            if old_idx in nodes_oldnew.keys():\n",
    "                graph_nodes_fin[seqid][nodes_oldnew[old_idx]] = node_name\n",
    "    return graph_nodes_fin\n",
    "\n",
    "graph_nodes_fin = filter_and_reindex_graph_nodes(graph_nodes, nodes_oldnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from graphfp.layers import FingerprintLayer, LinearRegressionLayer, GraphConvLayer\n",
    "from graphfp.utils import initialize_network\n",
    "from pyflatten import flatten\n",
    "\n",
    "layers = [GraphConvLayer(weights_shape=(36, 36), biases_shape=(1, 36)),\n",
    "          FingerprintLayer(weights_shape=(36, 36), biases_shape=(1, 36)),\n",
    "          LinearRegressionLayer(weights_shape=(36, 1), biases_shape=(1, 1)),\n",
    "]\n",
    "\n",
    "wb = initialize_network(layers_spec=layers)\n",
    "wb_vect, unflattener = flatten(wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "def batch_sample(inputs, nodes_nbrs, graph_idxs, n_graphs):\n",
    "    \"\"\"\n",
    "    Randomly samples n_graphs from all of the graphs, returns new inputs,\n",
    "    node_nbr dictionary, and graph_idx dictionary.\n",
    "    \"\"\"\n",
    "    samp_graph_idxs = dict(sample(graph_idxs.items(), n_graphs))\n",
    "    assert len(samp_graph_idxs) == n_graphs, \"There was an error in sampling.\"\n",
    "    concat_samp_idxs = np.concatenate([v for k, v in sorted(samp_graph_idxs.items())])\n",
    "    # print('Samp Idxs Shape')\n",
    "    # print(concat_samp_idxs.shape)\n",
    "    samp_nodes_nbrs = {i: nodes_nbrs[i] for i in concat_samp_idxs}\n",
    "    assert len(samp_nodes_nbrs) == len(concat_samp_idxs)\n",
    "\n",
    "    samp_inputs, samp_nodes_oldnew, samp_nodes_newold = reindex_data_matrix(samp_graph_idxs, inputs)\n",
    "    \n",
    "    samp_nodes_nbrs = filter_and_reindex_nodes_and_neighbors(samp_nodes_nbrs, samp_nodes_oldnew)\n",
    "    samp_graph_idxs = filter_and_reindex_graph_idxs(samp_graph_idxs, samp_nodes_oldnew)\n",
    "    \n",
    "    return samp_inputs, samp_nodes_nbrs, samp_graph_idxs\n",
    "\n",
    "n_sampled_graphs = 100\n",
    "samp_inputs, samp_nodes_nbrs, samp_graph_idxs = batch_sample(graph_arr_fin, nodes_nbrs_fin, graph_idxs_fin, n_sampled_graphs)\n",
    "\n",
    "assert samp_inputs.shape[1] == 36\n",
    "assert len(samp_nodes_nbrs) == samp_inputs.shape[0]\n",
    "assert len(samp_graph_idxs) == n_sampled_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scratchpad cell\n",
    "samp_graph_idxs = dict(sample(graph_idxs.items(), 10))\n",
    "assert len(samp_graph_idxs) == 10\n",
    "concat_samp_idxs = np.concatenate([i for i in samp_graph_idxs.values()])\n",
    "samp_nodes_nbrs = {i: nodes_nbrs[i] for i in concat_samp_idxs}\n",
    "assert len(samp_nodes_nbrs) == len(concat_samp_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Used in conjunction with train_loss function in cell below.\n",
    "from graphfp.binary_matrix_utils import to_sparse_format, to_scipy_csr_matrix\n",
    "# samp_graph_arr, samp_node_nbrs, samp_graph_idx = batch_sample(graph_arr_fin, nodes_nbrs_fin, graph_idxs_fin, 10)\n",
    "node_rows, node_cols, ones = to_sparse_format(nodes_nbrs_fin)\n",
    "# nodes_nbrs_sparse = to_scipy_csr_matrix(nodes_nbrs_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622671"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes_nbrs_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<622671x622671 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 2990113 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix \n",
    "nodes_nbrs_compressed = csr_matrix((ones, (node_rows, node_cols)), shape=(len(nodes_nbrs_fin), len(nodes_nbrs_fin)))\n",
    "nodes_nbrs_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%prun\n",
    "def predict(wb_struct, inputs, nodes_nbrs_compressed, graph_idxs, layers):\n",
    "    curr_inputs = inputs\n",
    "    \n",
    "    for i, layer in enumerate(layers):\n",
    "        wb = wb_struct['layer{0}_{1}'.format(i, layer)]\n",
    "        curr_inputs = layer.forward_pass(wb, curr_inputs, nodes_nbrs_compressed, graph_idxs)\n",
    "    return curr_inputs\n",
    "\n",
    "\n",
    "predict(wb, graph_arr_fin, nodes_nbrs_compressed, graph_idxs_fin, layers).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "\n",
    "# Prototype train_loss function\n",
    "wb_vect, unflattener = flatten(wb)\n",
    "\n",
    "def get_actual(graph_idxs, df, preds):\n",
    "    sorted_graphs = sorted(graph_idxs.keys())\n",
    "    # print(sorted_graphs)\n",
    "    sorted_resistances = df[df['seqid'].isin(sorted_graphs)].set_index('seqid').ix[sorted_graphs]['FPV'].values\n",
    "    # print(sorted_resistances)\n",
    "    actual = sorted_resistances.reshape(preds.shape)\n",
    "    \n",
    "    return actual\n",
    "\n",
    "train_losses = []\n",
    "preds_iter = []\n",
    "actual_iter = []\n",
    "\n",
    "def train_loss(wb_vect, unflattener):\n",
    "    \n",
    "    # Old version - sample one random one each time.\n",
    "    # ----------------------------------------------\n",
    "    # samp_graph_arr, samp_nodes_nbrs, samp_graph_idxs = batch_sample(graph_arr_fin, nodes_nbrs_fin, graph_idxs_fin, 1)\n",
    "    # wb_struct = unflattener(wb_vect)\n",
    "    # preds = predict(wb_struct, samp_graph_arr, samp_nodes_nbrs, samp_graph_idxs, layers)\n",
    "    \n",
    "    # New version - train on just one sample.\n",
    "    # Uses code in cell above.\n",
    "    # ---------------------------------------\n",
    "    wb_struct = unflattener(wb_vect)\n",
    "    preds = predict(wb_struct, graph_arr_fin, nodes_nbrs_compressed, graph_idxs_fin, layers)\n",
    "    graph_scores = get_actual(graph_idxs_fin, df, preds)\n",
    "    mse = np.mean(np.power(preds - graph_scores, 2))\n",
    "    \n",
    "    train_losses.append(mse)\n",
    "    preds_iter.append(preds)\n",
    "    actual_iter.append(graph_scores)\n",
    "    # print(mse)\n",
    "    return mse\n",
    "\n",
    "train_loss(wb_vect, unflattener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 882.02 MiB, increment: 0.04 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "gradfunc = grad(train_loss)  # how do I pass in kwargs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphfp.optimizers import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 881.77 MiB, increment: 0.42 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "import gc\n",
    "from time import time\n",
    "training_losses = []\n",
    "def callback(wb, i):\n",
    "    start = time()\n",
    "    tl = train_loss(*flatten(wb))\n",
    "    if i % 1 == 0:\n",
    "        print(tl, time() - start)\n",
    "    training_losses.append(tl)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2372.87628307 1.4468610286712646\n",
      "2334.75186471 1.9351251125335693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.00254475,  0.00205365,  0.00074579, ...,  0.00180891,\n",
       "         0.00183889,  0.0009858 ]),\n",
       " <function pyflatten.flatten.<locals>.unflatten>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam(gradfunc, wb, callback=callback, num_iters=2)\n",
    "# wb_vect, unflattener = adam(gradfunc, wb, callback=callback, num_iters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAECCAYAAAAFL5eMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15941f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from autograd.core import getval\n",
    "\n",
    "plt.plot([getval(i) for i in train_losses])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
